{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Quick HTML Tutorial](#quick-html-tutorial)\n",
    "* [HTML Tags and Attributes](#class-and-id-attributes)\n",
    "* [Web Scraping with Beautiful Soup](#web-scraping-with-beautiful-soup)\n",
    "* [Getting HTML data](#requests)\n",
    "* [Scraping a Website from the internet](#scraping-a-webpage-on-the-internet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick HTML Tutorial\n",
    "\n",
    "Web pages are written using HTML (hyper text markup language) and CSS (cascading style sheets). HTML provides the structure of the and the text that is to be displayed; CSS is responsible for visual and aural layout i.e. the font, colors, styling, etc.  \n",
    "\n",
    "### HTML\n",
    "1. HTML is used to give structure to the page. \n",
    "2. The HTML langugage comprises *elements*, which are used to *markup* the content i.e. label the text (or other content like image, video) as headings, paragraphs, lists, etc. \n",
    "3. The elements are defined through the use of tags. For most elements, there is an *opening tag* `<tagname>` and a *closing tag* `<tagname>`. For example: `<p>The first paragraph </p>` represents the paragraph element through the use of `<p>` tags\n",
    "\n",
    "Reference: https://www.w3.org/standards/webdesign/htmlcss\n",
    "\n",
    "**Let's now** open \"day9-example-webpage.html\" in the browser. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting a webpage \n",
    "\n",
    "To scrape a webpage, we should get a sense of its HTML. Web browsers generally allow us to inspect the HTML and CSS of websites.  \n",
    "\n",
    "**Accessing the HTML on Chrome and Firefox:**\n",
    "- Right click anywhere on the page and click on \"Inspect\" / \"Inspect Element\" in dropdown menu. \n",
    "- If you are a Safari or Internet Explorer user, the process may be slightly different. \n",
    "\n",
    "#### day9-example-webpage.html \n",
    "\n",
    "This example webpage has the following elements: \n",
    "1. A main `html` element \n",
    "    2. Body element, nested in the html element\n",
    "        3. 1 `h1` element, 3 paragraph element `p` \n",
    "            4. 3 anchor elements `a` - all nested in the last paragraph element.  \n",
    "\n",
    "2. Thus, the HTML element is the root element. The body element is the child of HTML and parent to three elements, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Tags and Attributes\n",
    "\n",
    "1. Attributes provide additional information about tags\n",
    "2. Attributes are always specified in the start tag\n",
    "3. Attributes usually come in name/value pairs like: `name=\"value\"`. \n",
    "\n",
    "In the example webapge, the second and the third `<p>` tags have a *class* attribute. The value of the class attribute is `\"title\"` and `\"story\"` respectively.  \n",
    "\n",
    "An *anchor tag* generally has the href attribute, which states the URL of the webpage. \n",
    "\n",
    "### class and id attributes \n",
    "Most elements' tags have either a class or an id attribute. These attributes are used to style the element. \n",
    "\n",
    "No two elements will have the same value for the id attribute but may share the values for the class attributes.  \n",
    "\n",
    "Reference: https://www.w3schools.com/html/html_attributes.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Practice (5 minutes)\n",
    "\n",
    "1. Inspect the three anchor tags in the example webpage. What are the different attributes and their values in the anchor tags? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Anchor tag 1 attributes: class, id, href. Values are respectively sister, link1, http://example.com/elsie\n",
    "- Anchor tag 2 attributes: class, id, href. Values are respectively sister, link2, http://example.com/lacie\n",
    "- Acnhor tag 3 attributes: id, href. Values are respectively link3, http://example.com/tillie\n",
    "\n",
    "```html\n",
    "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>; \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping with Beautiful Soup\n",
    "\n",
    "The Beautiful Soup library allows us to represent the webpage in nested strucuture and reach different elements through use of different functions. \n",
    "\n",
    "Since we have the html file for `\"day9-example-webpage.html\"` on our computer, we can open it as a file using the `open()` function in the read mode. \n",
    "\n",
    "**BeautifulSoup Module Documentation**: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#quick-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to import the BeautifulSoup class from the beautiful soup module. (It is called the bs4 module)\n",
    "\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode \n",
    "f = open('day9-example-webpage.html', 'r')\n",
    "\n",
    "# Read the html data from the file, which is basically text data :-) \n",
    "# Use the read() function that can read all the text lines from any file \n",
    "text = f.read() \n",
    "\n",
    "# Close the file! Always close the file!\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's output the html text we read from 9-example-webpage.html\n",
    "text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to create a soup object before we can start using the functions in the module\n",
    "# To do so, we need to call BeautifulSoup() function with two arguments: html text and 'html.parser' \n",
    "\n",
    "soup = BeautifulSoup(text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets reprint text but this time we can \"prettify\" it\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do some basic navigation on the nested structure \n",
    "soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will print the opening and closing tags with the enclosed text \n",
    "print(soup.h1)\n",
    "\n",
    "# Will print the text enclosed between <h1> and </h1> i.e. Sample Webpage \n",
    "print(soup.h1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that it outputs the first paragraph, does not output the other two paragraph elements \n",
    "soup.p, soup.p.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Functions from Beautiful Soup Module\n",
    "\n",
    "1. `soup.find_all(tagname)`: This will return a list of all the tags that match the specified tag name. We can also specify the attributes of class and id as second arguments for further filtering.  \n",
    "\n",
    "2. `soup.find(tagname)`: This will return first tag that matches the specified tag name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all anchor_tags\n",
    "anchor_tags = soup.find_all('a')\n",
    "\n",
    "print(len(anchor_tags))\n",
    "anchor_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all anchor tags with class = \"sister\"\n",
    "anchor_tags_class = soup.find_all('a', class_ = 'sister')\n",
    "anchor_tags_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all anchor tags with id = \"link1\"\n",
    "anchor_tags_id = soup.find_all('a', id = \"link1\")\n",
    "anchor_tags_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding paragraph that has class=\"title\"\n",
    "para_second = soup.find('p', class_=\"title\")\n",
    "para_second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Practice (15 minutes)\n",
    "\n",
    "1. Anchor tags practice: \n",
    "    - Create an empty list `a_text`\n",
    "    - Create a for loop to loop through `anchor_tags` and append the text of each anchor tag to `a_text`. \n",
    "    - Print `a_text` after the for loop. **Expected Output**: The list `a_text` should be `[\"Elsie\", \"Lacie\", \"Tillie\"]`.\n",
    "\n",
    "2. Use `find_all()` to find all paragraph elements. Store the result of `find_all` in a variable `para_tags`. Print the length of `para_tags`. **Expected Output: 3**\n",
    "\n",
    "3. Use `find()` to find the `h1` tag.\n",
    "\n",
    "4. Use `find()` to find the `p` tag that has `class = \"story\"` and assign it to a variable `para_third`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_tags = soup.find_all('a')\n",
    "anchor_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1 \n",
    "a_text = [] \n",
    "\n",
    "for item in anchor_tags: \n",
    "    tag_text = item.text  \n",
    "    a_text.append(tag_text)\n",
    "    \n",
    "a_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2 \n",
    "para_tags = soup.find_all(\"p\")\n",
    "len(para_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3 \n",
    "soup.find('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 4 \n",
    "para_third = soup.find('p', class_=\"story\")\n",
    "para_third\n",
    "\n",
    "# Print the text in the third <p> tag\n",
    "print(para_third.text)\n",
    "\n",
    "# para_third has three more tags within it. We can use find and find_all functions on para_third too \n",
    "para_third.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the attribute values of tags\n",
    "# In this case, let's print the href attribute of all anchor tags\n",
    "href_list = [] \n",
    "\n",
    "for item in anchor_tags:\n",
    "    link = item['id']\n",
    "    print(link)\n",
    "    href_list.append(link)\n",
    "    \n",
    "print(href_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping a webpage on the internet \n",
    "\n",
    "Can everyone access this webpage?: https://www.imdb.com/chart/top/\n",
    "\n",
    "**Our Goal:** Scrape the webpage to get the following details on IMDB's top 250 movies - movie title, release year, rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Practice (15 minutes)\n",
    "\n",
    "1. Which tag encloses the text \"Top Rated Movies\"? \n",
    "\n",
    "2. Which tag encloses the text \"Top Rated Movies by Genre\"? \n",
    "\n",
    "3. Which tag encloses the text \"The Shawshank Redemption\"? \n",
    "    - What are the attributes-values of that tag? \n",
    "    - What is the parent tag of this tag? \n",
    "    \n",
    "4. When inspecting the web page, can you identify the tag that is the parent to all the movies? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's scrape it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the module\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's request the data from https://www.imdb.com/chart/top/ using the get function \n",
    "# This will return a response \n",
    "\n",
    "url = \"https://www.imdb.com/chart/top/\"\n",
    "response = requests.get(url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different kinds of status codes \n",
    "# Status Code 404 - Page not found \n",
    "# Status Code 400 - Internet connection refused \n",
    "\n",
    "# Status Code 200 - request was successful, we can use response.text to access the HTML of the webpage \n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# Getting the html for https://www.imdb.com/chart/top/ by using the response.text \n",
    "html_text = response.text \n",
    "\n",
    "# make a soup\n",
    "soup = BeautifulSoup(html_text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all title columns\n",
    "title_columns = soup.findAll(class_=\"titleColumn\")\n",
    "for i in range(250):\n",
    "    print(title_columns[i].text)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.9.12 ('icpsr39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "793173ac31d6a2c33b964e93d6beb990e4e6a719190bc1945591b45858f43f14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
